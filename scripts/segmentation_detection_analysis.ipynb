{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D医学图像分割检测与评估系统\n",
    "\n",
    "本notebook用于检测和评估3D CT扫描的分割模型性能，包括：\n",
    "- 数据加载与探索\n",
    "- 模型推理与预测\n",
    "- 评估指标计算（Dice系数、IoU、成功率）\n",
    "- 2D/3D可视化\n",
    "- 综合统计报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置与依赖导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import marching_cubes\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 设置matplotlib中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. U-Net模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net模型定义完成\n"
     ]
    }
   ],
   "source": [
    "class UNet2D(nn.Module):\n",
    "    \"\"\"2D U-Net模型用于医学图像分割\"\"\"\n",
    "    \n",
    "    def __init__(self, in_ch=1, out_ch=117, features=[32, 64, 128, 256]):\n",
    "        super(UNet2D, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 编码器\n",
    "        in_channels = in_ch\n",
    "        for feature in features:\n",
    "            self.encoders.append(self._block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # 瓶颈层\n",
    "        self.bottleneck = self._block(features[-1], features[-1]*2)\n",
    "        \n",
    "        # 解码器\n",
    "        for feature in reversed(features):\n",
    "            self.decoders.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.decoders.append(self._block(feature*2, feature))\n",
    "        \n",
    "        # 最终输出层\n",
    "        self.final_conv = nn.Conv2d(features[0], out_ch, kernel_size=1)\n",
    "    \n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码路径\n",
    "        skip_connections = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # 瓶颈\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # 解码路径\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        for idx in range(0, len(self.decoders), 2):\n",
    "            x = self.decoders[idx](x)\n",
    "            skip = skip_connections[idx//2]\n",
    "            if x.shape != skip.shape:\n",
    "                x = nn.functional.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat([skip, x], dim=1)\n",
    "            x = self.decoders[idx+1](x)\n",
    "        \n",
    "        return self.final_conv(x)\n",
    "\n",
    "print(\"U-Net模型定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据集类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集类定义完成\n"
     ]
    }
   ],
   "source": [
    "class CTSegmentationDataset(Dataset):\n",
    "    \"\"\"CT图像分割数据集\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, subject_ids, label_map=None, target_shape=(256, 256)):\n",
    "        self.data_dir = data_dir\n",
    "        self.subject_ids = subject_ids\n",
    "        self.target_shape = target_shape\n",
    "        self.samples = []\n",
    "        \n",
    "        # 如果没有提供label_map，自动生成\n",
    "        if label_map is None:\n",
    "            seg_files = sorted(os.listdir(os.path.join(data_dir, subject_ids[0], 'segmentations')))\n",
    "            self.label_map = {f: i for i, f in enumerate(seg_files)}\n",
    "        else:\n",
    "            self.label_map = label_map\n",
    "        \n",
    "        self.num_classes = len(self.label_map)\n",
    "        \n",
    "        # 收集所有切片\n",
    "        for subj_id in subject_ids:\n",
    "            ct_path = os.path.join(data_dir, subj_id, 'ct.nii.gz')\n",
    "            if os.path.exists(ct_path):\n",
    "                ct_img = nib.load(ct_path)\n",
    "                num_slices = ct_img.shape[2]\n",
    "                for slice_idx in range(num_slices):\n",
    "                    self.samples.append((subj_id, slice_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def _normalize_ct(self, ct_slice):\n",
    "        \"\"\"使用百分位数归一化CT切片\"\"\"\n",
    "        p1, p99 = np.percentile(ct_slice, (1, 99))\n",
    "        ct_slice = np.clip(ct_slice, p1, p99)\n",
    "        ct_slice = (ct_slice - p1) / (p99 - p1 + 1e-8)\n",
    "        return ct_slice\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        subj_id, slice_idx = self.samples[idx]\n",
    "        \n",
    "        # 加载CT切片\n",
    "        ct_path = os.path.join(self.data_dir, subj_id, 'ct.nii.gz')\n",
    "        ct_img = nib.load(ct_path)\n",
    "        ct_data = ct_img.get_fdata()\n",
    "        ct_slice = ct_data[:, :, slice_idx]\n",
    "        \n",
    "        # 归一化和调整大小\n",
    "        ct_slice = self._normalize_ct(ct_slice)\n",
    "        ct_slice = resize(ct_slice, self.target_shape, anti_aliasing=True, preserve_range=True)\n",
    "        \n",
    "        # 加载分割掩码\n",
    "        seg_dir = os.path.join(self.data_dir, subj_id, 'segmentations')\n",
    "        mask = np.zeros((self.num_classes,) + self.target_shape, dtype=np.float32)\n",
    "        \n",
    "        for seg_file, channel_idx in self.label_map.items():\n",
    "            seg_path = os.path.join(seg_dir, seg_file)\n",
    "            if os.path.exists(seg_path):\n",
    "                seg_img = nib.load(seg_path)\n",
    "                seg_data = seg_img.get_fdata()\n",
    "                seg_slice = seg_data[:, :, slice_idx]\n",
    "                seg_slice = resize(seg_slice, self.target_shape, order=0, anti_aliasing=False, preserve_range=True)\n",
    "                mask[channel_idx] = (seg_slice > 0).astype(np.float32)\n",
    "        \n",
    "        # 转换为tensor\n",
    "        ct_tensor = torch.from_numpy(ct_slice).unsqueeze(0).float()\n",
    "        mask_tensor = torch.from_numpy(mask).float()\n",
    "        \n",
    "        return ct_tensor, mask_tensor, subj_id, slice_idx\n",
    "\n",
    "print(\"数据集类定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 评估指标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估指标函数定义完成\n"
     ]
    }
   ],
   "source": [
    "def dice_coefficient(pred, target, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    计算Dice系数\n",
    "    \n",
    "    Args:\n",
    "        pred: 预测掩码 (B, C, H, W) 或 (C, H, W)\n",
    "        target: 真实掩码 (B, C, H, W) 或 (C, H, W)\n",
    "        epsilon: 平滑项\n",
    "    \n",
    "    Returns:\n",
    "        Dice系数 (每个类别一个值)\n",
    "    \"\"\"\n",
    "    pred = (pred > 0.5).float()\n",
    "    \n",
    "    # 如果是4D张量，在batch维度上求平均\n",
    "    if pred.dim() == 4:\n",
    "        dims = (0, 2, 3)\n",
    "    else:\n",
    "        dims = (1, 2)\n",
    "    \n",
    "    intersection = (pred * target).sum(dim=dims)\n",
    "    union = pred.sum(dim=dims) + target.sum(dim=dims)\n",
    "    \n",
    "    dice = (2.0 * intersection + epsilon) / (union + epsilon)\n",
    "    return dice\n",
    "\n",
    "def iou_score(pred, target, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    计算IoU (Intersection over Union)\n",
    "    \n",
    "    Args:\n",
    "        pred: 预测掩码 (B, C, H, W) 或 (C, H, W)\n",
    "        target: 真实掩码 (B, C, H, W) 或 (C, H, W)\n",
    "        epsilon: 平滑项\n",
    "    \n",
    "    Returns:\n",
    "        IoU分数 (每个类别一个值)\n",
    "    \"\"\"\n",
    "    pred = (pred > 0.5).float()\n",
    "    \n",
    "    if pred.dim() == 4:\n",
    "        dims = (0, 2, 3)\n",
    "    else:\n",
    "        dims = (1, 2)\n",
    "    \n",
    "    intersection = (pred * target).sum(dim=dims)\n",
    "    union = pred.sum(dim=dims) + target.sum(dim=dims) - intersection\n",
    "    \n",
    "    iou = (intersection + epsilon) / (union + epsilon)\n",
    "    return iou\n",
    "\n",
    "def calculate_success_rate(dice_scores, threshold=0.7):\n",
    "    \"\"\"\n",
    "    计算检测成功率（Dice系数高于阈值的比例）\n",
    "    \n",
    "    Args:\n",
    "        dice_scores: Dice系数数组\n",
    "        threshold: 成功阈值\n",
    "    \n",
    "    Returns:\n",
    "        成功率 (0-1)\n",
    "    \"\"\"\n",
    "    return (dice_scores > threshold).float().mean().item()\n",
    "\n",
    "def hausdorff_distance_2d(pred, target):\n",
    "    \"\"\"\n",
    "    计算简化的2D Hausdorff距离\n",
    "    （仅计算边界点之间的最大距离）\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import binary_erosion\n",
    "    \n",
    "    pred_np = pred.cpu().numpy()\n",
    "    target_np = target.cpu().numpy()\n",
    "    \n",
    "    # 提取边界\n",
    "    pred_boundary = pred_np ^ binary_erosion(pred_np)\n",
    "    target_boundary = target_np ^ binary_erosion(target_np)\n",
    "    \n",
    "    # 如果没有边界点，返回0\n",
    "    if not pred_boundary.any() or not target_boundary.any():\n",
    "        return 0.0\n",
    "    \n",
    "    # 获取边界点坐标\n",
    "    pred_points = np.argwhere(pred_boundary)\n",
    "    target_points = np.argwhere(target_boundary)\n",
    "    \n",
    "    # 计算Hausdorff距离\n",
    "    from scipy.spatial.distance import cdist\n",
    "    distances_pred_to_target = cdist(pred_points, target_points).min(axis=1).max()\n",
    "    distances_target_to_pred = cdist(target_points, pred_points).min(axis=1).max()\n",
    "    \n",
    "    return max(distances_pred_to_target, distances_target_to_pred)\n",
    "\n",
    "print(\"评估指标函数定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 数据探索与统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 8 个受试者: ['s0000', 's0001', 's0002', 's0003', 's0004', 's0006', 's0009', 'scripts']\n",
      "\n",
      "=== 数据集统计信息 ===\n",
      "s0000: CT形状=(294, 192, 179), 分割数量=117\n",
      "s0001: CT形状=(249, 188, 213), 分割数量=117\n",
      "s0002: CT形状=(185, 128, 101), 分割数量=117\n",
      "s0003: CT形状=(127, 127, 126), 分割数量=117\n",
      "s0004: CT形状=(255, 177, 440), 分割数量=117\n",
      "s0006: CT形状=(216, 216, 217), 分割数量=117\n",
      "s0009: CT形状=(119, 119, 185), 分割数量=117\n"
     ]
    }
   ],
   "source": [
    "# 设置数据目录\n",
    "DATA_DIR = '/home/hzhang02/dataset'\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, 'outputs')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 获取所有受试者ID\n",
    "all_subjects = [d for d in os.listdir(DATA_DIR) if d.startswith('s') and os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "all_subjects = sorted(all_subjects)\n",
    "\n",
    "print(f\"找到 {len(all_subjects)} 个受试者: {all_subjects}\")\n",
    "\n",
    "# 统计信息\n",
    "print(\"\\n=== 数据集统计信息 ===\")\n",
    "for subj_id in all_subjects:\n",
    "    ct_path = os.path.join(DATA_DIR, subj_id, 'ct.nii.gz')\n",
    "    seg_dir = os.path.join(DATA_DIR, subj_id, 'segmentations')\n",
    "    \n",
    "    if os.path.exists(ct_path):\n",
    "        ct_img = nib.load(ct_path)\n",
    "        shape = ct_img.shape\n",
    "        num_segs = len(os.listdir(seg_dir)) if os.path.exists(seg_dir) else 0\n",
    "        print(f\"{subj_id}: CT形状={shape}, 分割数量={num_segs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "创建并保存标签映射到 /home/hzhang02/dataset/outputs/label_map.json\n",
      "\n",
      "解剖结构数量: 117\n",
      "\n",
      "前10个解剖结构:\n",
      "  0: adrenal_gland_left\n",
      "  1: adrenal_gland_right\n",
      "  2: aorta\n",
      "  3: atrial_appendage_left\n",
      "  4: autochthon_left\n",
      "  5: autochthon_right\n",
      "  6: brachiocephalic_trunk\n",
      "  7: brachiocephalic_vein_left\n",
      "  8: brachiocephalic_vein_right\n",
      "  9: brain\n"
     ]
    }
   ],
   "source": [
    "# 加载标签映射\n",
    "label_map_path = os.path.join(OUTPUT_DIR, 'label_map.json')\n",
    "\n",
    "if os.path.exists(label_map_path):\n",
    "    with open(label_map_path, 'r') as f:\n",
    "        label_map = json.load(f)\n",
    "    print(f\"\\n从 {label_map_path} 加载标签映射\")\n",
    "else:\n",
    "    # 创建新的标签映射\n",
    "    seg_dir = os.path.join(DATA_DIR, all_subjects[0], 'segmentations')\n",
    "    seg_files = sorted(os.listdir(seg_dir))\n",
    "    label_map = {f: i for i, f in enumerate(seg_files)}\n",
    "    \n",
    "    # 保存标签映射\n",
    "    with open(label_map_path, 'w') as f:\n",
    "        json.dump(label_map, f, indent=2)\n",
    "    print(f\"\\n创建并保存标签映射到 {label_map_path}\")\n",
    "\n",
    "print(f\"\\n解剖结构数量: {len(label_map)}\")\n",
    "print(f\"\\n前10个解剖结构:\")\n",
    "for i, (name, idx) in enumerate(list(label_map.items())[:10]):\n",
    "    print(f\"  {idx}: {name.replace('.nii.gz', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型加载与推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到训练好的模型检查点\n",
      "请先运行 train_unet.py 训练模型\n"
     ]
    }
   ],
   "source": [
    "# 查找最新的检查点\n",
    "checkpoint_files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith('checkpoint_') and f.endswith('.pth')]\n",
    "\n",
    "if checkpoint_files:\n",
    "    # 按epoch排序，选择最新的\n",
    "    checkpoint_files = sorted(checkpoint_files, key=lambda x: int(x.split('_')[1].split('.')[0].replace('epoch', '')))\n",
    "    latest_checkpoint = checkpoint_files[-1]\n",
    "    checkpoint_path = os.path.join(OUTPUT_DIR, latest_checkpoint)\n",
    "    \n",
    "    print(f\"找到检查点: {latest_checkpoint}\")\n",
    "    \n",
    "    # 创建模型\n",
    "    model = UNet2D(in_ch=1, out_ch=len(label_map), features=[32, 64, 128, 256])\n",
    "    \n",
    "    # 加载权重\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"成功加载模型，epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "    if 'val_dice' in checkpoint:\n",
    "        print(f\"验证集Dice系数: {checkpoint['val_dice']:.4f}\")\n",
    "    \n",
    "    model_loaded = True\n",
    "else:\n",
    "    print(\"未找到训练好的模型检查点\")\n",
    "    print(\"请先运行 train_unet.py 训练模型\")\n",
    "    model_loaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 分割检测与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    # 选择一个测试受试者\n",
    "    test_subject = all_subjects[0]  # 可以修改为其他受试者\n",
    "    \n",
    "    print(f\"\\n=== 对受试者 {test_subject} 进行分割检测 ===\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    test_dataset = CTSegmentationDataset(\n",
    "        DATA_DIR, \n",
    "        [test_subject], \n",
    "        label_map=label_map, \n",
    "        target_shape=(256, 256)\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    print(f\"测试切片数量: {len(test_dataset)}\")\n",
    "    \n",
    "    # 存储所有预测和指标\n",
    "    all_dice_scores = []\n",
    "    all_iou_scores = []\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_images = []\n",
    "    \n",
    "    # 推理\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks, subj_ids, slice_indices) in enumerate(tqdm(test_loader, desc=\"推理中\")):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            \n",
    "            # 计算指标\n",
    "            dice = dice_coefficient(predictions, masks)\n",
    "            iou = iou_score(predictions, masks)\n",
    "            \n",
    "            all_dice_scores.append(dice.cpu())\n",
    "            all_iou_scores.append(iou.cpu())\n",
    "            \n",
    "            # 保存部分样本用于可视化\n",
    "            if batch_idx < 5:  # 保存前5个batch\n",
    "                all_predictions.append(predictions.cpu())\n",
    "                all_targets.append(masks.cpu())\n",
    "                all_images.append(images.cpu())\n",
    "    \n",
    "    # 合并所有指标\n",
    "    all_dice_scores = torch.cat(all_dice_scores, dim=0)\n",
    "    all_iou_scores = torch.cat(all_iou_scores, dim=0)\n",
    "    \n",
    "    print(\"\\n推理完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 评估指标统计与分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    # 计算每个类别的平均指标\n",
    "    mean_dice_per_class = all_dice_scores.mean(dim=0)\n",
    "    mean_iou_per_class = all_iou_scores.mean(dim=0)\n",
    "    std_dice_per_class = all_dice_scores.std(dim=0)\n",
    "    std_iou_per_class = all_iou_scores.std(dim=0)\n",
    "    \n",
    "    # 总体指标\n",
    "    overall_dice = mean_dice_per_class.mean().item()\n",
    "    overall_iou = mean_iou_per_class.mean().item()\n",
    "    \n",
    "    # 成功率（使用不同阈值）\n",
    "    success_rate_50 = calculate_success_rate(mean_dice_per_class, threshold=0.5)\n",
    "    success_rate_70 = calculate_success_rate(mean_dice_per_class, threshold=0.7)\n",
    "    success_rate_80 = calculate_success_rate(mean_dice_per_class, threshold=0.8)\n",
    "    \n",
    "    print(\"\\n=== 总体评估指标 ===\")\n",
    "    print(f\"平均Dice系数: {overall_dice:.4f}\")\n",
    "    print(f\"平均IoU分数: {overall_iou:.4f}\")\n",
    "    print(f\"\\n成功率 (Dice > 0.5): {success_rate_50:.2%}\")\n",
    "    print(f\"成功率 (Dice > 0.7): {success_rate_70:.2%}\")\n",
    "    print(f\"成功率 (Dice > 0.8): {success_rate_80:.2%}\")\n",
    "    \n",
    "    # 创建详细的结果DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        '解剖结构': [k.replace('.nii.gz', '') for k in label_map.keys()],\n",
    "        'Dice系数': mean_dice_per_class.numpy(),\n",
    "        'Dice标准差': std_dice_per_class.numpy(),\n",
    "        'IoU分数': mean_iou_per_class.numpy(),\n",
    "        'IoU标准差': std_iou_per_class.numpy()\n",
    "    })\n",
    "    \n",
    "    # 按Dice系数排序\n",
    "    results_df = results_df.sort_values('Dice系数', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== 前10个表现最好的解剖结构 ===\")\n",
    "    print(results_df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(\"\\n=== 前10个表现最差的解剖结构 ===\")\n",
    "    print(results_df.tail(10).to_string(index=False))\n",
    "    \n",
    "    # 保存完整结果\n",
    "    results_path = os.path.join(OUTPUT_DIR, f'evaluation_results_{test_subject}.csv')\n",
    "    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n完整结果已保存到: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 可视化 - 评估指标分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Dice系数直方图\n",
    "    axes[0, 0].hist(mean_dice_per_class.numpy(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(overall_dice, color='red', linestyle='--', linewidth=2, label=f'Mean: {overall_dice:.3f}')\n",
    "    axes[0, 0].set_xlabel('Dice Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Dice Score Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # 2. IoU分数直方图\n",
    "    axes[0, 1].hist(mean_iou_per_class.numpy(), bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[0, 1].axvline(overall_iou, color='red', linestyle='--', linewidth=2, label=f'Mean: {overall_iou:.3f}')\n",
    "    axes[0, 1].set_xlabel('IoU Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('IoU Score Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Dice vs IoU散点图\n",
    "    axes[1, 0].scatter(mean_dice_per_class.numpy(), mean_iou_per_class.numpy(), alpha=0.6)\n",
    "    axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.5, label='y=x')\n",
    "    axes[1, 0].set_xlabel('Dice Score')\n",
    "    axes[1, 0].set_ylabel('IoU Score')\n",
    "    axes[1, 0].set_title('Dice vs IoU Correlation')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # 4. 成功率柱状图\n",
    "    thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    success_rates = [calculate_success_rate(mean_dice_per_class, t) for t in thresholds]\n",
    "    axes[1, 1].bar([str(t) for t in thresholds], [sr * 100 for sr in success_rates], \n",
    "                   edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[1, 1].set_xlabel('Dice Threshold')\n",
    "    axes[1, 1].set_ylabel('Success Rate (%)')\n",
    "    axes[1, 1].set_title('Success Rate at Different Thresholds')\n",
    "    axes[1, 1].grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    metrics_plot_path = os.path.join(OUTPUT_DIR, f'metrics_distribution_{test_subject}.png')\n",
    "    plt.savefig(metrics_plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n指标分布图已保存到: {metrics_plot_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 可视化 - 前20名表现最好/最差的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # 最好的20个\n",
    "    top_20 = results_df.head(20)\n",
    "    y_pos = np.arange(len(top_20))\n",
    "    axes[0].barh(y_pos, top_20['Dice系数'], xerr=top_20['Dice标准差'], \n",
    "                 align='center', alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0].set_yticks(y_pos)\n",
    "    axes[0].set_yticklabels(top_20['解剖结构'], fontsize=8)\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_xlabel('Dice Score')\n",
    "    axes[0].set_title('Top 20 Best Performing Structures')\n",
    "    axes[0].grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    # 最差的20个\n",
    "    bottom_20 = results_df.tail(20)\n",
    "    y_pos = np.arange(len(bottom_20))\n",
    "    axes[1].barh(y_pos, bottom_20['Dice系数'], xerr=bottom_20['Dice标准差'],\n",
    "                 align='center', alpha=0.7, color='red', edgecolor='black')\n",
    "    axes[1].set_yticks(y_pos)\n",
    "    axes[1].set_yticklabels(bottom_20['解剖结构'], fontsize=8)\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_xlabel('Dice Score')\n",
    "    axes[1].set_title('Top 20 Worst Performing Structures')\n",
    "    axes[1].grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    ranking_plot_path = os.path.join(OUTPUT_DIR, f'structure_ranking_{test_subject}.png')\n",
    "    plt.savefig(ranking_plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n结构排名图已保存到: {ranking_plot_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 可视化 - 2D分割结果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded and all_predictions:\n",
    "    # 选择中间的一个batch进行可视化\n",
    "    batch_idx = len(all_predictions) // 2\n",
    "    sample_images = all_images[batch_idx]\n",
    "    sample_preds = all_predictions[batch_idx]\n",
    "    sample_targets = all_targets[batch_idx]\n",
    "    \n",
    "    # 选择几个有代表性的解剖结构\n",
    "    structures_to_viz = ['liver', 'heart', 'kidney_left', 'kidney_right', 'lung_upper_lobe_left', 'aorta']\n",
    "    channel_indices = []\n",
    "    \n",
    "    for struct in structures_to_viz:\n",
    "        for filename, idx in label_map.items():\n",
    "            if struct in filename.lower():\n",
    "                channel_indices.append((idx, filename.replace('.nii.gz', '')))\n",
    "                break\n",
    "    \n",
    "    # 选择第一个样本\n",
    "    sample_idx = 0\n",
    "    img = sample_images[sample_idx, 0].numpy()\n",
    "    \n",
    "    # 创建可视化\n",
    "    n_structures = len(channel_indices)\n",
    "    fig, axes = plt.subplots(n_structures, 3, figsize=(15, 5 * n_structures))\n",
    "    \n",
    "    if n_structures == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, (ch_idx, struct_name) in enumerate(channel_indices):\n",
    "        pred = (sample_preds[sample_idx, ch_idx] > 0.5).numpy()\n",
    "        target = sample_targets[sample_idx, ch_idx].numpy()\n",
    "        \n",
    "        # 计算该结构的Dice\n",
    "        dice = dice_coefficient(\n",
    "            sample_preds[sample_idx:sample_idx+1, ch_idx:ch_idx+1],\n",
    "            sample_targets[sample_idx:sample_idx+1, ch_idx:ch_idx+1]\n",
    "        ).item()\n",
    "        \n",
    "        # CT图像\n",
    "        axes[row, 0].imshow(img, cmap='gray')\n",
    "        axes[row, 0].set_title(f'{struct_name}\\nOriginal CT')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # 真实掩码\n",
    "        axes[row, 1].imshow(img, cmap='gray')\n",
    "        axes[row, 1].imshow(target, cmap='Reds', alpha=0.5)\n",
    "        axes[row, 1].set_title('Ground Truth')\n",
    "        axes[row, 1].axis('off')\n",
    "        \n",
    "        # 预测掩码\n",
    "        axes[row, 2].imshow(img, cmap='gray')\n",
    "        axes[row, 2].imshow(pred, cmap='Greens', alpha=0.5)\n",
    "        axes[row, 2].set_title(f'Prediction\\nDice: {dice:.3f}')\n",
    "        axes[row, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    seg_viz_path = os.path.join(OUTPUT_DIR, f'segmentation_visualization_{test_subject}.png')\n",
    "    plt.savefig(seg_viz_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n分割可视化已保存到: {seg_viz_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 可视化 - 多切片对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded and all_predictions:\n",
    "    # 选择一个特定的解剖结构（例如肝脏）\n",
    "    target_structure = 'liver'\n",
    "    target_channel = None\n",
    "    \n",
    "    for filename, idx in label_map.items():\n",
    "        if target_structure in filename.lower():\n",
    "            target_channel = idx\n",
    "            target_name = filename.replace('.nii.gz', '')\n",
    "            break\n",
    "    \n",
    "    if target_channel is not None:\n",
    "        # 收集该结构的多个切片\n",
    "        n_slices = min(16, len(all_images[0]))  # 最多16个切片\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(n_slices):\n",
    "            batch_idx = i // len(all_images[0])\n",
    "            sample_idx = i % len(all_images[0])\n",
    "            \n",
    "            if batch_idx >= len(all_images):\n",
    "                break\n",
    "            \n",
    "            img = all_images[batch_idx][sample_idx, 0].numpy()\n",
    "            pred = (all_predictions[batch_idx][sample_idx, target_channel] > 0.5).numpy()\n",
    "            target = all_targets[batch_idx][sample_idx, target_channel].numpy()\n",
    "            \n",
    "            # 叠加显示\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].contour(target, colors='red', linewidths=2, alpha=0.7)\n",
    "            axes[i].contour(pred, colors='green', linewidths=2, alpha=0.7, linestyles='dashed')\n",
    "            axes[i].set_title(f'Slice {i+1}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        # 添加图例\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color='red', linewidth=2, label='Ground Truth'),\n",
    "            Line2D([0], [0], color='green', linewidth=2, linestyle='dashed', label='Prediction')\n",
    "        ]\n",
    "        fig.legend(handles=legend_elements, loc='upper center', ncol=2, fontsize=12)\n",
    "        fig.suptitle(f'Multi-slice Segmentation Comparison: {target_name}', fontsize=16, y=0.98)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        multi_slice_path = os.path.join(OUTPUT_DIR, f'multi_slice_{target_structure}_{test_subject}.png')\n",
    "        plt.savefig(multi_slice_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\n多切片对比图已保存到: {multi_slice_path}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 3D可视化 - 单个结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_mesh(volume, threshold=0.5, step_size=1):\n",
    "    \"\"\"\n",
    "    使用Marching Cubes算法从3D体积创建网格\n",
    "    \n",
    "    Args:\n",
    "        volume: 3D numpy数组\n",
    "        threshold: 阈值\n",
    "        step_size: 采样步长\n",
    "    \n",
    "    Returns:\n",
    "        vertices, faces: 网格的顶点和面\n",
    "    \"\"\"\n",
    "    try:\n",
    "        verts, faces, normals, values = marching_cubes(\n",
    "            volume, \n",
    "            level=threshold, \n",
    "            step_size=step_size,\n",
    "            allow_degenerate=False\n",
    "        )\n",
    "        return verts, faces\n",
    "    except Exception as e:\n",
    "        print(f\"创建网格失败: {e}\")\n",
    "        return None, None\n",
    "\n",
    "if model_loaded:\n",
    "    print(\"\\n=== 创建3D可视化 ===\")\n",
    "    \n",
    "    # 选择几个重要的解剖结构进行3D可视化\n",
    "    structures_3d = ['liver', 'heart', 'kidney_left']\n",
    "    \n",
    "    for struct_name in structures_3d:\n",
    "        # 找到对应的通道\n",
    "        target_channel = None\n",
    "        for filename, idx in label_map.items():\n",
    "            if struct_name in filename.lower():\n",
    "                target_channel = idx\n",
    "                full_name = filename.replace('.nii.gz', '')\n",
    "                break\n",
    "        \n",
    "        if target_channel is None:\n",
    "            print(f\"未找到结构: {struct_name}\")\n",
    "            continue\n",
    "        \n",
    "        # 加载真实的3D分割数据\n",
    "        seg_path = os.path.join(DATA_DIR, test_subject, 'segmentations', f'{full_name}.nii.gz')\n",
    "        if not os.path.exists(seg_path):\n",
    "            print(f\"文件不存在: {seg_path}\")\n",
    "            continue\n",
    "        \n",
    "        seg_img = nib.load(seg_path)\n",
    "        seg_data = seg_img.get_fdata()\n",
    "        \n",
    "        # 降采样以加快处理速度\n",
    "        step_size = 2\n",
    "        \n",
    "        print(f\"\\n处理 {full_name}...\")\n",
    "        print(f\"数据形状: {seg_data.shape}\")\n",
    "        \n",
    "        # 创建网格\n",
    "        verts, faces = create_3d_mesh(seg_data, threshold=0.5, step_size=step_size)\n",
    "        \n",
    "        if verts is not None and faces is not None:\n",
    "            print(f\"顶点数: {len(verts)}, 面数: {len(faces)}\")\n",
    "            \n",
    "            # 创建3D可视化\n",
    "            fig = go.Figure(data=[\n",
    "                go.Mesh3d(\n",
    "                    x=verts[:, 0],\n",
    "                    y=verts[:, 1],\n",
    "                    z=verts[:, 2],\n",
    "                    i=faces[:, 0],\n",
    "                    j=faces[:, 1],\n",
    "                    k=faces[:, 2],\n",
    "                    opacity=0.7,\n",
    "                    color='lightblue',\n",
    "                    flatshading=True,\n",
    "                    name=full_name\n",
    "                )\n",
    "            ])\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=f'3D Visualization: {full_name}',\n",
    "                scene=dict(\n",
    "                    xaxis_title='X',\n",
    "                    yaxis_title='Y',\n",
    "                    zaxis_title='Z',\n",
    "                    aspectmode='data'\n",
    "                ),\n",
    "                width=800,\n",
    "                height=800\n",
    "            )\n",
    "            \n",
    "            # 保存HTML\n",
    "            html_path = os.path.join(OUTPUT_DIR, f'3d_{struct_name}_{test_subject}.html')\n",
    "            fig.write_html(html_path)\n",
    "            print(f\"3D可视化已保存到: {html_path}\")\n",
    "            \n",
    "            # 在notebook中显示\n",
    "            fig.show()\n",
    "        else:\n",
    "            print(f\"无法为 {full_name} 创建3D网格\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 3D可视化 - 多个结构组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    print(\"\\n=== 创建多结构组合3D可视化 ===\")\n",
    "    \n",
    "    # 选择多个结构\n",
    "    multi_structures = ['heart', 'liver', 'kidney_left', 'kidney_right']\n",
    "    colors = ['red', 'brown', 'blue', 'lightblue']\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for struct_name, color in zip(multi_structures, colors):\n",
    "        # 找到对应的通道\n",
    "        target_channel = None\n",
    "        for filename, idx in label_map.items():\n",
    "            if struct_name in filename.lower():\n",
    "                full_name = filename.replace('.nii.gz', '')\n",
    "                break\n",
    "        \n",
    "        # 加载3D分割数据\n",
    "        seg_path = os.path.join(DATA_DIR, test_subject, 'segmentations', f'{full_name}.nii.gz')\n",
    "        if not os.path.exists(seg_path):\n",
    "            continue\n",
    "        \n",
    "        seg_img = nib.load(seg_path)\n",
    "        seg_data = seg_img.get_fdata()\n",
    "        \n",
    "        # 创建网格（使用较大的step_size以减少顶点数）\n",
    "        verts, faces = create_3d_mesh(seg_data, threshold=0.5, step_size=3)\n",
    "        \n",
    "        if verts is not None and faces is not None:\n",
    "            print(f\"{full_name}: {len(verts)} vertices, {len(faces)} faces\")\n",
    "            \n",
    "            fig.add_trace(go.Mesh3d(\n",
    "                x=verts[:, 0],\n",
    "                y=verts[:, 1],\n",
    "                z=verts[:, 2],\n",
    "                i=faces[:, 0],\n",
    "                j=faces[:, 1],\n",
    "                k=faces[:, 2],\n",
    "                opacity=0.6,\n",
    "                color=color,\n",
    "                name=full_name,\n",
    "                flatshading=True\n",
    "            ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'3D Multi-Structure Visualization: {test_subject}',\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=1000,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # 保存HTML\n",
    "    multi_html_path = os.path.join(OUTPUT_DIR, f'3d_multi_structure_{test_subject}.html')\n",
    "    fig.write_html(multi_html_path)\n",
    "    print(f\"\\n多结构3D可视化已保存到: {multi_html_path}\")\n",
    "    \n",
    "    # 显示\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 综合报告生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" \" * 15 + \"3D医学图像分割检测综合报告\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n测试受试者: {test_subject}\")\n",
    "    print(f\"测试切片数量: {len(test_dataset)}\")\n",
    "    print(f\"解剖结构数量: {len(label_map)}\")\n",
    "    \n",
    "    print(\"\\n【总体性能指标】\")\n",
    "    print(f\"  平均Dice系数: {overall_dice:.4f}\")\n",
    "    print(f\"  平均IoU分数: {overall_iou:.4f}\")\n",
    "    \n",
    "    print(\"\\n【检测成功率】\")\n",
    "    print(f\"  Dice > 0.50: {success_rate_50:>6.2%}  ({int(success_rate_50 * len(label_map))}/{len(label_map)}个结构)\")\n",
    "    print(f\"  Dice > 0.70: {success_rate_70:>6.2%}  ({int(success_rate_70 * len(label_map))}/{len(label_map)}个结构)\")\n",
    "    print(f\"  Dice > 0.80: {success_rate_80:>6.2%}  ({int(success_rate_80 * len(label_map))}/{len(label_map)}个结构)\")\n",
    "    \n",
    "    print(\"\\n【表现最好的5个结构】\")\n",
    "    for i, row in results_df.head(5).iterrows():\n",
    "        print(f\"  {row['解剖结构']:<30} Dice: {row['Dice系数']:.4f}  IoU: {row['IoU分数']:.4f}\")\n",
    "    \n",
    "    print(\"\\n【表现最差的5个结构】\")\n",
    "    for i, row in results_df.tail(5).iterrows():\n",
    "        print(f\"  {row['解剖结构']:<30} Dice: {row['Dice系数']:.4f}  IoU: {row['IoU分数']:.4f}\")\n",
    "    \n",
    "    print(\"\\n【统计摘要】\")\n",
    "    print(f\"  Dice系数中位数: {results_df['Dice系数'].median():.4f}\")\n",
    "    print(f\"  Dice系数标准差: {results_df['Dice系数'].std():.4f}\")\n",
    "    print(f\"  最高Dice系数: {results_df['Dice系数'].max():.4f}\")\n",
    "    print(f\"  最低Dice系数: {results_df['Dice系数'].min():.4f}\")\n",
    "    \n",
    "    print(\"\\n【输出文件】\")\n",
    "    output_files = [\n",
    "        f'evaluation_results_{test_subject}.csv',\n",
    "        f'metrics_distribution_{test_subject}.png',\n",
    "        f'structure_ranking_{test_subject}.png',\n",
    "        f'segmentation_visualization_{test_subject}.png',\n",
    "    ]\n",
    "    \n",
    "    for filename in output_files:\n",
    "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"  ✓ {filename}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" \" * 20 + \"报告生成完成！\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 交互式分析工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_loaded:\n",
    "    # 创建交互式Plotly图表用于探索所有结构的性能\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # 添加散点图\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=results_df['Dice系数'],\n",
    "        y=results_df['IoU分数'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=results_df['Dice系数'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title='Dice Score')\n",
    "        ),\n",
    "        text=results_df['解剖结构'],\n",
    "        hovertemplate='<b>%{text}</b><br>' +\n",
    "                      'Dice: %{x:.4f}<br>' +\n",
    "                      'IoU: %{y:.4f}<br>' +\n",
    "                      '<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Interactive Performance Analysis: Dice vs IoU',\n",
    "        xaxis_title='Dice Score',\n",
    "        yaxis_title='IoU Score',\n",
    "        width=900,\n",
    "        height=600,\n",
    "        hovermode='closest'\n",
    "    )\n",
    "    \n",
    "    # 保存交互式图表\n",
    "    interactive_path = os.path.join(OUTPUT_DIR, f'interactive_analysis_{test_subject}.html')\n",
    "    fig.write_html(interactive_path)\n",
    "    print(f\"\\n交互式分析图表已保存到: {interactive_path}\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本notebook实现了完整的3D医学图像分割检测与评估流程：\n",
    "\n",
    "1. **数据加载**: 支持多受试者CT扫描和117个解剖结构的分割标注\n",
    "2. **模型推理**: 使用训练好的U-Net模型进行2D切片分割\n",
    "3. **评估指标**: 计算Dice系数、IoU、检测成功率等多项指标\n",
    "4. **2D可视化**: 展示分割结果、指标分布、结构排名等\n",
    "5. **3D可视化**: 生成交互式3D网格模型\n",
    "6. **综合报告**: 生成详细的性能分析报告\n",
    "\n",
    "### 使用建议：\n",
    "- 修改 `test_subject` 变量来测试不同的受试者\n",
    "- 调整 `structures_to_viz` 和 `structures_3d` 来可视化不同的解剖结构\n",
    "- 修改成功率阈值来评估不同的性能标准\n",
    "- 使用交互式图表深入探索各个结构的性能\n",
    "\n",
    "### 改进方向：\n",
    "1. 实现真正的3D模型预测（而非2D切片）\n",
    "2. 添加更多评估指标（Hausdorff距离、表面距离等）\n",
    "3. 支持批量评估多个受试者\n",
    "4. 添加与其他SOTA模型的对比\n",
    "5. 实现在线推理API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (claude_env)",
   "language": "python",
   "name": "claude_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
